{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d33983d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>waistline</th>\n",
       "      <th>sight_left</th>\n",
       "      <th>sight_right</th>\n",
       "      <th>hear_left</th>\n",
       "      <th>hear_right</th>\n",
       "      <th>SBP</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL_chole</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>urine_protein</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>SGOT_AST</th>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <th>gamma_GTP</th>\n",
       "      <th>SMK_stat_type_cd</th>\n",
       "      <th>DRK_YN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>47.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  age  height  weight  waistline  sight_left  sight_right  hear_left  \\\n",
       "0  Male   35     170      75       90.0         1.0          1.0        1.0   \n",
       "1  Male   30     180      80       89.0         0.9          1.2        1.0   \n",
       "2  Male   40     165      75       91.0         1.2          1.5        1.0   \n",
       "3  Male   50     175      80       91.0         1.5          1.2        1.0   \n",
       "4  Male   50     165      60       80.0         1.0          1.2        1.0   \n",
       "\n",
       "   hear_right    SBP  ...  LDL_chole  triglyceride  hemoglobin  urine_protein  \\\n",
       "0         1.0  120.0  ...      126.0          92.0        17.1            1.0   \n",
       "1         1.0  130.0  ...      148.0         121.0        15.8            1.0   \n",
       "2         1.0  120.0  ...       74.0         104.0        15.8            1.0   \n",
       "3         1.0  145.0  ...      104.0         106.0        17.6            1.0   \n",
       "4         1.0  138.0  ...      117.0         104.0        13.8            1.0   \n",
       "\n",
       "   serum_creatinine  SGOT_AST  SGOT_ALT  gamma_GTP  SMK_stat_type_cd  DRK_YN  \n",
       "0               1.0      21.0      35.0       40.0               1.0       Y  \n",
       "1               0.9      20.0      36.0       27.0               3.0       N  \n",
       "2               0.9      47.0      32.0       68.0               1.0       N  \n",
       "3               1.1      29.0      34.0       18.0               1.0       N  \n",
       "4               0.8      19.0      12.0       25.0               1.0       N  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Read the data file using the prropriate separator as input to read_csv()\n",
    "\n",
    "df = pd.read_csv('smoking_driking_dataset_Ver01.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f4b097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(991346, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e04204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                 0\n",
       "age                 0\n",
       "height              0\n",
       "weight              0\n",
       "waistline           0\n",
       "sight_left          0\n",
       "sight_right         0\n",
       "hear_left           0\n",
       "hear_right          0\n",
       "SBP                 0\n",
       "DBP                 0\n",
       "BLDS                0\n",
       "tot_chole           0\n",
       "HDL_chole           0\n",
       "LDL_chole           0\n",
       "triglyceride        0\n",
       "hemoglobin          0\n",
       "urine_protein       0\n",
       "serum_creatinine    0\n",
       "SGOT_AST            0\n",
       "SGOT_ALT            0\n",
       "gamma_GTP           0\n",
       "SMK_stat_type_cd    0\n",
       "DRK_YN              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is NaN in the dataset\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b90f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 991346 entries, 0 to 991345\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   sex               991346 non-null  object \n",
      " 1   age               991346 non-null  int64  \n",
      " 2   height            991346 non-null  int64  \n",
      " 3   weight            991346 non-null  int64  \n",
      " 4   waistline         991346 non-null  float64\n",
      " 5   sight_left        991346 non-null  float64\n",
      " 6   sight_right       991346 non-null  float64\n",
      " 7   hear_left         991346 non-null  float64\n",
      " 8   hear_right        991346 non-null  float64\n",
      " 9   SBP               991346 non-null  float64\n",
      " 10  DBP               991346 non-null  float64\n",
      " 11  BLDS              991346 non-null  float64\n",
      " 12  tot_chole         991346 non-null  float64\n",
      " 13  HDL_chole         991346 non-null  float64\n",
      " 14  LDL_chole         991346 non-null  float64\n",
      " 15  triglyceride      991346 non-null  float64\n",
      " 16  hemoglobin        991346 non-null  float64\n",
      " 17  urine_protein     991346 non-null  float64\n",
      " 18  serum_creatinine  991346 non-null  float64\n",
      " 19  SGOT_AST          991346 non-null  float64\n",
      " 20  SGOT_ALT          991346 non-null  float64\n",
      " 21  gamma_GTP         991346 non-null  float64\n",
      " 22  SMK_stat_type_cd  991346 non-null  float64\n",
      " 23  DRK_YN            991346 non-null  object \n",
      "dtypes: float64(19), int64(3), object(2)\n",
      "memory usage: 181.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# looking at column info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63fd945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping smokers because we will not be anaylzing it\n",
    "df.drop(columns=['SMK_stat_type_cd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fe91f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>waistline</th>\n",
       "      <th>sight_left</th>\n",
       "      <th>sight_right</th>\n",
       "      <th>hear_left</th>\n",
       "      <th>hear_right</th>\n",
       "      <th>SBP</th>\n",
       "      <th>...</th>\n",
       "      <th>HDL_chole</th>\n",
       "      <th>LDL_chole</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>urine_protein</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>SGOT_AST</th>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <th>gamma_GTP</th>\n",
       "      <th>DRK_YN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>47.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  height  weight  waistline  sight_left  sight_right  hear_left  \\\n",
       "0    1   35     170      75       90.0         1.0          1.0        1.0   \n",
       "1    1   30     180      80       89.0         0.9          1.2        1.0   \n",
       "2    1   40     165      75       91.0         1.2          1.5        1.0   \n",
       "3    1   50     175      80       91.0         1.5          1.2        1.0   \n",
       "4    1   50     165      60       80.0         1.0          1.2        1.0   \n",
       "\n",
       "   hear_right    SBP  ...  HDL_chole  LDL_chole  triglyceride  hemoglobin  \\\n",
       "0         1.0  120.0  ...       48.0      126.0          92.0        17.1   \n",
       "1         1.0  130.0  ...       55.0      148.0         121.0        15.8   \n",
       "2         1.0  120.0  ...       41.0       74.0         104.0        15.8   \n",
       "3         1.0  145.0  ...       76.0      104.0         106.0        17.6   \n",
       "4         1.0  138.0  ...       61.0      117.0         104.0        13.8   \n",
       "\n",
       "   urine_protein  serum_creatinine  SGOT_AST  SGOT_ALT  gamma_GTP  DRK_YN  \n",
       "0            1.0               1.0      21.0      35.0       40.0       1  \n",
       "1            1.0               0.9      20.0      36.0       27.0       0  \n",
       "2            1.0               0.9      47.0      32.0       68.0       0  \n",
       "3            1.0               1.1      29.0      34.0       18.0       0  \n",
       "4            1.0               0.8      19.0      12.0       25.0       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making all gender binary\n",
    "df['sex'] = (df['sex'] == 'Male').astype(int)\n",
    "#making DRK_YN binary\n",
    "df['DRK_YN'] = (df['DRK_YN'] == 'Y').astype(int)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed74e85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>waistline</th>\n",
       "      <th>sight_left</th>\n",
       "      <th>sight_right</th>\n",
       "      <th>hear_left</th>\n",
       "      <th>hear_right</th>\n",
       "      <th>SBP</th>\n",
       "      <th>...</th>\n",
       "      <th>tot_chole</th>\n",
       "      <th>HDL_chole</th>\n",
       "      <th>LDL_chole</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>urine_protein</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>SGOT_AST</th>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <th>gamma_GTP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>228.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>47.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>150</td>\n",
       "      <td>55</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>196.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>175</td>\n",
       "      <td>65</td>\n",
       "      <td>84.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>217.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>175</td>\n",
       "      <td>75</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  height  weight  waistline  sight_left  sight_right  hear_left  \\\n",
       "0    1   35     170      75       90.0         1.0          1.0        1.0   \n",
       "1    1   30     180      80       89.0         0.9          1.2        1.0   \n",
       "2    1   40     165      75       91.0         1.2          1.5        1.0   \n",
       "3    1   50     175      80       91.0         1.5          1.2        1.0   \n",
       "4    1   50     165      60       80.0         1.0          1.2        1.0   \n",
       "5    1   50     165      55       75.0         1.2          1.5        1.0   \n",
       "6    0   45     150      55       69.0         0.5          0.4        1.0   \n",
       "7    1   35     175      65       84.2         1.2          1.0        1.0   \n",
       "8    1   55     170      75       84.0         1.2          0.9        1.0   \n",
       "9    1   40     175      75       82.0         1.5          1.5        1.0   \n",
       "\n",
       "   hear_right    SBP  ...  tot_chole  HDL_chole  LDL_chole  triglyceride  \\\n",
       "0         1.0  120.0  ...      193.0       48.0      126.0          92.0   \n",
       "1         1.0  130.0  ...      228.0       55.0      148.0         121.0   \n",
       "2         1.0  120.0  ...      136.0       41.0       74.0         104.0   \n",
       "3         1.0  145.0  ...      201.0       76.0      104.0         106.0   \n",
       "4         1.0  138.0  ...      199.0       61.0      117.0         104.0   \n",
       "5         1.0  142.0  ...      218.0       77.0       95.0         232.0   \n",
       "6         1.0  101.0  ...      196.0       66.0      115.0          75.0   \n",
       "7         1.0  132.0  ...      185.0       58.0      107.0         101.0   \n",
       "8         1.0  145.0  ...      217.0       56.0      141.0         100.0   \n",
       "9         1.0  132.0  ...      195.0       60.0      118.0          83.0   \n",
       "\n",
       "   hemoglobin  urine_protein  serum_creatinine  SGOT_AST  SGOT_ALT  gamma_GTP  \n",
       "0        17.1            1.0               1.0      21.0      35.0       40.0  \n",
       "1        15.8            1.0               0.9      20.0      36.0       27.0  \n",
       "2        15.8            1.0               0.9      47.0      32.0       68.0  \n",
       "3        17.6            1.0               1.1      29.0      34.0       18.0  \n",
       "4        13.8            1.0               0.8      19.0      12.0       25.0  \n",
       "5        13.8            3.0               0.8      29.0      40.0       37.0  \n",
       "6        12.3            1.0               0.8      19.0      12.0       12.0  \n",
       "7        14.4            1.0               0.8      18.0      18.0       35.0  \n",
       "8        15.1            1.0               0.8      32.0      23.0       26.0  \n",
       "9        13.9            1.0               0.9      21.0      38.0       16.0  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['DRK_YN']\n",
    "x = df.drop('DRK_YN', axis=1)\n",
    "x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b282874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "40    130385\n",
      "50    129434\n",
      "45    118355\n",
      "55    111223\n",
      "60    106063\n",
      "35     84726\n",
      "30     77600\n",
      "25     64370\n",
      "65     52961\n",
      "70     50666\n",
      "75     25333\n",
      "20     21971\n",
      "80     14968\n",
      "85      3291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['age'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "993611fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))  # Adjust the size as needed\n",
    "plt.hist(df['age'], bins=20, edgecolor='black')  # Adjust the number of bins as needed\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_counts = df['sex'].value_counts()\n",
    "plt.figure(figsize=(7, 5))  # Adjust the size as needed\n",
    "sex_counts.plot(kind='bar')\n",
    "plt.title('Sex Distribution')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)  # Keeps the labels horizontal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drinker_counts = df['DRK_YN'].value_counts()\n",
    "plt.figure(figsize=(7, 5))  # Adjust the size as needed\n",
    "drinker_counts.plot(kind='bar')\n",
    "plt.title('Drinker Distribution')\n",
    "plt.xlabel('Drinker')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)  # Keeps the labels horizontal\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695b308",
   "metadata": {},
   "source": [
    "x and y are setup, here. We can try PCA dimensionality reduction and see if it yields better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a90a07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to explain 95% variance: 17\n",
      "[0.18615714 0.1026232  0.08788977 0.07392775 0.06568667 0.05632473\n",
      " 0.05069812 0.04808058 0.04251237 0.04052846 0.03765877 0.03372251\n",
      " 0.03147249 0.03029349 0.02579443 0.02104819 0.01967803]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Fit PCA without specifying the number of components\n",
    "pca = PCA()\n",
    "pca.fit(x_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the cumulative variance\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(cumulative_variance)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Determine the number of components for desired explained variance, e.g., 95%\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "print(f\"Number of components to explain 95% variance: {n_components}\")\n",
    "\n",
    "# Apply PCA with the determined number of components\n",
    "pca_optimal = PCA(n_components=n_components)\n",
    "x_pca = pca_optimal.fit_transform(x_scaled)\n",
    "\n",
    "print(pca_optimal.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898636e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d52dd4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sambryant/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=  11.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  10.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  10.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  11.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.9; total time=  10.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   9.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  12.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=  10.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.9; total time=   9.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  12.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=1.0; total time=  10.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  13.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  12.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  12.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  11.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  10.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=  12.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=  11.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   7.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   9.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   6.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   8.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.9; total time=   9.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.9; total time=   9.5s\n",
      "Best Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.9}\n",
      "Improved Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "best_xgb = XGBClassifier(**best_params)\n",
    "best_xgb.fit(x_train, y_train)\n",
    "\n",
    "y_pred = best_xgb.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Improved Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e42190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "#PCA WITH LOG REGRESSION\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dfdc5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.19\n",
      "R² Score: 0.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Bayesian Ridge Regression model\n",
    "bayesian_ridge = BayesianRidge()\n",
    "\n",
    "bayesian_ridge.fit(x_train, y_train)\n",
    "\n",
    "y_pred = bayesian_ridge.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88cc301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.18\n",
      "R² Score: 0.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "catboost_model = CatBoostRegressor(verbose=0) \n",
    "\n",
    "catboost_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = catboost_model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "x = pd.DataFrame(scaled_x, columns=x.columns)\n",
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([x, y], axis=1)\n",
    "corr_matrix = combined_df.corr()\n",
    "plt.figure(figsize=(12, 8))  # Adjust the size as needed\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair plot\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.pairplot(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce928e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns: 2,3,4,10,11,12,13,17,22\n",
    "# converterd: ['age', 'height', 'weight', 'SBP', 'DBP', 'BLDS', 'tot_chole', 'hemoglobin', 'gamma_GTP']\n",
    "# these columns seem to have a high impact on the output of DRK_Y. There are a lot of no's and yes's.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2622c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnormalized data\n",
    "from sklearn.model_selection import train_test_split\n",
    "cols = ['sex','age', 'height', 'weight', 'waistline', 'sight_left', 'sight_right', 'DBP', 'triglyceride', 'hemoglobin', 'serum_creatinine', 'gamma_GTP']\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[cols], y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6083e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7cbf512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97afa56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aca6caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.64%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e560a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM RBF\n",
    "from sklearn.svm import SVC\n",
    "svc= SVC(kernel = 'rbf', C= 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(x_train, y_train)\n",
    "y_svc_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61aa5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svc = accuracy_score(y_test, y_svc_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_svc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb700b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_logreg_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_logreg = accuracy_score(y_test, y_logreg_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_logreg * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try PCA Dimensional Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca_result = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f520c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_columns = ['pca-1', 'pca-2', 'pca-3','pca-4', 'pca-5', 'pca-6','pca-7', 'pca-8', 'pca-9','pca-10']\n",
    "PCA_df = pd.DataFrame(pca_result, columns=pca_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ad2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try PCA with models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
